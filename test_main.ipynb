{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/home/xyang/miniconda3/envs/torch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from utils.feature_extractor import featureExtractor\n",
    "from utils.data_loader import TestDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def run_testing_on_dataset(trained_model, dataset_dir, GT_blurry, start, end, pbar):\n",
    "    correct_prediction_count = 0\n",
    "    img_list = os.listdir(dataset_dir)[start:end]\n",
    "    for ind, image_name in enumerate(img_list):\n",
    "        # Read the image\n",
    "        img = cv2.imread(os.path.join(dataset_dir, image_name), 0)\n",
    "\n",
    "        prediction = is_image_blurry(trained_model, img, threshold=0.5)\n",
    "\n",
    "        if(prediction == GT_blurry):\n",
    "            correct_prediction_count += 1\n",
    "        pbar.update(1)\n",
    "    accuracy = correct_prediction_count / len(img_list)\n",
    "    return(accuracy)\n",
    "\n",
    "\n",
    "def multi_thread_testing(trained_model, dataset_dir, GT_blurry, thread_num=4):\n",
    "    correct_prediction_count = 0\n",
    "    img_list = os.listdir(dataset_dir)\n",
    "    l = len(img_list)\n",
    "\n",
    "    thread_list = []\n",
    "    pbar = tqdm(total=l)\n",
    "    pbar.set_description(\"Testing: \")\n",
    "    result = []\n",
    "\n",
    "    for i in range(thread_num):\n",
    "        start = i * l // thread_num\n",
    "        end = (i + 1) * l // thread_num\n",
    "        t = threading.Thread(target=run_testing_on_dataset, args=(trained_model, \\\n",
    "                                                                  dataset_dir,\\\n",
    "                                                                  GT_blurry, \\\n",
    "                                                                  start, end, pbar))\n",
    "        t.start()\n",
    "        thread_list.append(t)\n",
    "\n",
    "    for t in thread_list:\n",
    "        result.extend(t.join())\n",
    "\n",
    "    pbar.close()\n",
    "    return result\n",
    "\n",
    "def is_image_blurry(trained_model, img, threshold=0.5):\n",
    "    feature_extractor = featureExtractor()\n",
    "    accumulator = []\n",
    "\n",
    "    # Resize the image by the downsampling factor\n",
    "    feature_extractor.resize_image(img, np.shape(img)[0], np.shape(img)[1])\n",
    "\n",
    "    # compute the image ROI using local entropy filter\n",
    "    feature_extractor.compute_roi()\n",
    "\n",
    "    # extract the blur features using DCT transform coefficients\n",
    "    extracted_features = feature_extractor.extract_feature()\n",
    "    extracted_features = np.array(extracted_features)\n",
    "\n",
    "    if(len(extracted_features) == 0):\n",
    "        return True\n",
    "    test_data_loader = DataLoader(TestDataset(extracted_features), batch_size=1, shuffle=False)\n",
    "\n",
    "    # trained_model.test()\n",
    "    for batch_num, input_data in enumerate(test_data_loader):\n",
    "        x = input_data\n",
    "        # x = x.to(device).float()\n",
    "        output = trained_model(x)\n",
    "        _, predicted_label = torch.max(output, 1)\n",
    "        accumulator.append(predicted_label.item())\n",
    "\n",
    "    prediction= np.mean(accumulator) < threshold\n",
    "    return(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m./trained_model/trained_model.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m trained_model \u001b[39m=\u001b[39m trained_model[\u001b[39m'\u001b[39m\u001b[39mmodel_state\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m trained_model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:607\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m             opened_file\u001b[39m.\u001b[39mseek(orig_position)\n\u001b[1;32m    606\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 607\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:882\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m    881\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m--> 882\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    884\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m    886\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:857\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m data_type, key, location, size \u001b[39m=\u001b[39m data\n\u001b[1;32m    856\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loaded_storages:\n\u001b[0;32m--> 857\u001b[0m     load_tensor(data_type, size, key, _maybe_decode_ascii(location))\n\u001b[1;32m    858\u001b[0m storage \u001b[39m=\u001b[39m loaded_storages[key]\n\u001b[1;32m    859\u001b[0m \u001b[39mreturn\u001b[39;00m storage\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:846\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    843\u001b[0m dtype \u001b[39m=\u001b[39m data_type(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    845\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, size, dtype)\u001b[39m.\u001b[39mstorage()\n\u001b[0;32m--> 846\u001b[0m loaded_storages[key] \u001b[39m=\u001b[39m restore_location(storage, location)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    176\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:151\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    150\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 151\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    152\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    153\u001b[0m             storage_type \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(torch\u001b[39m.\u001b[39mcuda, \u001b[39mtype\u001b[39m(obj)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:135\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    132\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    136\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    140\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "trained_model = torch.load('./trained_model/trained_model.pth')\n",
    "trained_model = trained_model['model_state']\n",
    "trained_model.eval()\n",
    "# trained_model = trained_model.to(device)\n",
    "\n",
    "dataset_dir = './dataset/defocused_blurred/'\n",
    "accuracy_blurry_images = run_testing_on_dataset(trained_model, dataset_dir, GT_blurry = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
